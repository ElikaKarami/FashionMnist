# -*- coding: utf-8 -*-
"""Elika's Fashion mnist

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oa8KIrzMojpWKVC_leyAorTnqYd8PWHo

#Fashion MNIST with CNN
"""
import streamlit as st

# Commented out IPython magic to ensure Python compatibility.
#Importing required libraries and packages
import tensorflow as tf
import keras
import matplotlib.pyplot as plt
import numpy as np
import keras.backend.tensorflow_backend as tb
tb._SYMBOLIC_SCOPE.value = True
import scipy
import cv2
from keras.models import model_from_json , load_model
# from keras.preprocessing import image
# from PIL import Image 

st.sidebar.title('Image Classifier')
st.sidebar.header('Navigation')
page = st.sidebar.radio(label = 'Goto', options = ['About', 'Technical Report','Image Prediction','Info'])
# st.sidebar.success('h',color_mode = )

fashion = keras.datasets.fashion_mnist
(X_train, y_train), (X_test, y_test) = fashion.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover','Dress', 'Coat', 'Sandel' ,'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

i = st.sidebar.slider('Trainset images' , max_value = 60000)
plt.figure()
plt.xticks([])
plt.yticks([])
plt.imshow(X_train[i])
plt.xlabel(class_names[y_train[i]], fontsize = 20)
st.sidebar.pyplot()

j = st.sidebar.slider('Test images' , max_value = 10000)
plt.figure()
plt.xticks([])
plt.yticks([])
plt.imshow(X_test[j])
plt.xlabel(class_names[y_test[j]], fontsize = 20)
st.sidebar.pyplot()
        

if page == 'About':
    st.title('Fashion MNIST image classification')
    st.write("""
    ## Dataset
    Fashion-MNIST is a dataset of [Zalando's article](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.
    Here's an example how the data looks (each class takes three-rows):
    """)
    st.image('/home/elika/Desktop/University_project_mnist/fashion-mnist-sprite.png', use_column_width = True)
    st.image('/home/elika/Desktop/University_project_mnist/embedding.gif', use_column_width = True)
    st.write('''It is a more challenging classification problem than MNIST and top results are achieved by deep learning convolutional neural networks with a classification accuracy of about 90% to 95% on the hold out test dataset.''')
    st.write(''' 
    ## Labels
    Each training and test example is assigned to one of the following labels:

    |Label|Description|
    |-----|-----------|
    |**0**|T-shirt/top|
    |**1**|Trouser|
    |**2**|Pullover|
    |**3**|Dress|
    |**4**|Coat|
    |**5**|Sandal|
    |**6**|Shirt|
    |**7**|Sneaker|
    |**8**|Bag|
    |**9**|Ankle boot|
    
    
    ''')
    st.write(''' For more info please visit [Zalando's github](https://github.com/zalandoresearch/fashion-mnist).''')
elif page == 'Technical Report':
    st.title('Technical Report')
    st.write(''' 
    ## Content
    Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.

    Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.

    The training and test data sets have 785 columns.

    The first column consists of the class labels, and represents the article of clothing.

    The rest of 784 columns (1-785) contain the pixel-values of the associated image.

    ## Train set images
    We add labels to the train set images, with the corresponding fashion item category.''')
    st.image('/home/elika/Downloads/showimage-edited.png', use_column_width = True)
    st.write('''
    ## Visulize input
    ''')
    st.image('/home/elika/Desktop/University_project_mnist/dress.png', use_column_width = True)
    st.write('''
    ## Train the model

    Build the model
    We will use a Sequential model.

    * The Sequential model is a linear stack of layers. It can be first initialized and then we add layers using add method or we can add all layers at init stage. The layers added are as follows:

    * Conv2D is a 2D Convolutional layer (i.e. spatial convolution over images). The parameters used are:

        * filters - the number of filters (Kernels) used with this layer; here filters = 16;
        * kernel_size - the dimmension of the Kernel: (5 x 5);
        * activation - is the activation function used, in this case relu;
        * kernel_initializer - the function used for initializing the kernel;
        * input_shape - is the shape of the image presented to the CNN

    * MaxPooling2D is a Max pooling operation for spatial data. Parameters used here are:
        * pool_size, in this case (2,2), representing the factors by which to downscale in both directions;
        * Conv2D with the following parameters:
            * filters: 8;
            * kernel_size : (5 x 5);
            * activation : relu;
    * MaxPooling2D with parameter:
        * pool_size : (2,2);

    * Flatten. This layer Flattens the input. Does not affect the batch size. It is used without parameters;

    * Dense. This layer is a regular fully-connected NN layer. It is used without parameters;
        * units - this is a positive integer, with the meaning: dimensionality of the output space; in this case is: 100;
        * activation - activation function : relu

    * Dense. This is the final layer (fully connected). It is used with the parameters:
        * units: the number of classes (in our case 10).
        * activation : softmax; for this final layer it is used softmax activation (standard for multiclass classification)

    Then we compile the model, specifying as well the following parameters:
    * loss
    * optimizer
    * metrics

    ''')
    st.write(''' 
    ## Model accuracy & error
    **Accuracy**: 0.899399995803833

    **Error**: 10.0600004196167
    ''')
    st.write('''
    ## Model accuracy & train-test loss plots

    ''')
    st.image('/home/elika/Downloads/plot50.png',use_column_width = True, caption = 'accuracy / epoch' )
    st.image('/home/elika/Downloads/plot52.png', use_column_width = True, caption = 'loss / epoch')



elif page == 'Image Prediction':
    st.title('Image Prediction')
    st.subheader('Use this model for predicting your clothing images.')
    #import data
    fashion = keras.datasets.fashion_mnist

    #load data
    (X_train, y_train), (X_test, y_test) = fashion.load_data()

    class_names = ['T-shirt/top', 'Trouser', 'Pullover','Dress', 'Coat', 'Sandel' ,'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    model = load_model('100epochs')


    file_types = ['png','jpg']
    image = st.file_uploader("Please choose a .png or .jpg photo:", type = file_types)
    if image is not None:
        st.write('your uploaded image:')
        st.image(image, width = 200)
        # image = Image.open(uploaded_file)
        file_bytes = np.asarray(bytearray(image.read()) , dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img , (28,28), interpolation=cv2.INTER_AREA)
        img = img.reshape(28, 28, 1)
        
        st.image(img, width = 50)
        img = np.expand_dims(img, axis=0)
        
        [predicted] = model.predict(img)
        print([predicted])
        predicted = predicted.tolist()
        for j in predicted:
            for i in class_names:
                if predicted.index(j) == class_names.index(i) and j==1.0:
                    st.write('The model prediction for this image is : ' + i)
         






        


            

    








